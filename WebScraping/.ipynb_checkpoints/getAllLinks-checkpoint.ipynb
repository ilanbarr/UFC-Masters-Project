{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b54609a4-c05e-4be3-b657-4d3058dcea87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9ab23c-bb78-464c-9aa4-2759cc76cbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 24 links from page 1\n",
      "Scraped 25 links from page 2\n",
      "Scraped 25 links from page 3\n",
      "Scraped 25 links from page 4\n",
      "Scraped 25 links from page 5\n",
      "Scraped 25 links from page 6\n",
      "Scraped 25 links from page 7\n",
      "Scraped 25 links from page 8\n",
      "Scraped 25 links from page 9\n",
      "Scraped 25 links from page 10\n",
      "Scraped 25 links from page 11\n",
      "Scraped 25 links from page 12\n",
      "Scraped 25 links from page 13\n",
      "Scraped 25 links from page 14\n",
      "Scraped 25 links from page 15\n",
      "Scraped 25 links from page 16\n",
      "Scraped 25 links from page 17\n",
      "Scraped 25 links from page 18\n",
      "Scraped 25 links from page 19\n",
      "Scraped 25 links from page 20\n",
      "Scraped 25 links from page 21\n",
      "Scraped 25 links from page 22\n",
      "Scraped 25 links from page 23\n",
      "Scraped 25 links from page 24\n",
      "Scraped 25 links from page 25\n",
      "Scraped 25 links from page 26\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_links(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all <a> tags with the specified class\n",
    "    event_links = soup.find_all('a', class_='b-link b-link_style_black')\n",
    "    \n",
    "    # Extract the href attribute (link URL) from each <a> tag\n",
    "    links = [link['href'] for link in event_links]\n",
    "    return links\n",
    "\n",
    "# Example usage\n",
    "base_url = \"http://www.ufcstats.com/statistics/events/completed?page=\"\n",
    "all_links = []\n",
    "\n",
    "# Loop through the range of pages you want to scrape\n",
    "for page_number in range(1, 27):  # Adjust the range as necessary\n",
    "    url = f\"{base_url}{page_number}\"\n",
    "    links = scrape_links(url)\n",
    "    all_links.extend(links)\n",
    "    print(f\"Scraped {len(links)} links from page {page_number}\")\n",
    "\n",
    "# all_links now contains all the extracted links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1886b4e5-d002-48fb-909d-fda40136e762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e4286e-24ce-493e-813c-0770a5b49b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "links_df = pd.DataFrame(all_links, columns=['URL'])\n",
    "links_df.to_csv('all_links.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
